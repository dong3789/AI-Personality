# Docker Compose ì„¤ê³„

## docker-compose.yml

```yaml
version: '3.8'

services:
  # Next.js ì• í”Œë¦¬ì¼€ì´ì…˜
  nextjs:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai-personality-nextjs
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - OLLAMA_API_URL=http://host.docker.internal:11434  # ë¡œì»¬ Ollama ì‚¬ìš©
      - DATABASE_PATH=/app/data/database.sqlite
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASS=${SMTP_PASS}
      - EMAIL_FROM=${EMAIL_FROM}
      - APP_URL=${APP_URL}
    volumes:
      - ./data:/app/data
      - ./.cache:/app/.cache
    ports:
      - "3000:3000"
    extra_hosts:
      - "host.docker.internal:host-gateway"  # ë¡œì»¬ í˜¸ìŠ¤íŠ¸ ì ‘ê·¼
    networks:
      - ai-personality-network

  # Caddy ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ (HTTPS)
  caddy:
    image: caddy:latest
    container_name: ai-personality-caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy-data:/data
      - caddy-config:/config
    depends_on:
      - nextjs
    networks:
      - ai-personality-network

volumes:
  caddy-data:
    driver: local
  caddy-config:
    driver: local

networks:
  ai-personality-network:
    driver: bridge
```

## Caddyfile

```
{
    email your-email@example.com
}

ai-personality.yourdomain.com {
    reverse_proxy nextjs:3000

    # ë¡œê¹…
    log {
        output file /var/log/caddy/access.log
        format json
    }

    # ì••ì¶•
    encode gzip

    # í—¬ìŠ¤ì²´í¬ ì—”ë“œí¬ì¸íŠ¸
    handle /health {
        reverse_proxy nextjs:3000
    }
}
```

## Dockerfile (Next.js)

```dockerfile
# Stage 1: Dependencies
FROM node:20-alpine AS deps
WORKDIR /app

COPY package.json package-lock.json ./
RUN npm ci

# Stage 2: Builder
FROM node:20-alpine AS builder
WORKDIR /app

COPY --from=deps /app/node_modules ./node_modules
COPY . .

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV NEXT_TELEMETRY_DISABLED 1

# ë¹Œë“œ
RUN npm run build

# Stage 3: Runner
FROM node:20-alpine AS runner
WORKDIR /app

ENV NODE_ENV production
ENV NEXT_TELEMETRY_DISABLED 1

# ì‚¬ìš©ì ìƒì„±
RUN addgroup --system --gid 1001 nodejs
RUN adduser --system --uid 1001 nextjs

# í•„ìš”í•œ íŒŒì¼ë§Œ ë³µì‚¬
COPY --from=builder /app/public ./public
COPY --from=builder /app/.next/standalone ./
COPY --from=builder /app/.next/static ./.next/static

# ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
RUN mkdir -p /app/data /app/.cache
RUN chown -R nextjs:nodejs /app

USER nextjs

EXPOSE 3000

ENV PORT 3000
ENV HOSTNAME "0.0.0.0"

CMD ["node", "server.js"]
```

## next.config.js (Standalone ëª¨ë“œ)

```javascript
/** @type {import('next').NextConfig} */
const nextConfig = {
  output: 'standalone',

  // ì´ë¯¸ì§€ ìµœì í™”
  images: {
    domains: ['avatars.githubusercontent.com'],
  },

  // í™˜ê²½ ë³€ìˆ˜ ê²€ì¦
  env: {
    OLLAMA_API_URL: process.env.OLLAMA_API_URL,
    APP_URL: process.env.APP_URL,
  },
};

module.exports = nextConfig;
```

## ë°°í¬ ìŠ¤í¬ë¦½íŠ¸

### deploy.sh (ë¡œì»¬ Ollama ì‚¬ìš©)
```bash
#!/bin/bash

echo "ğŸš€ AI Personality Analyzer ë°°í¬ ì‹œì‘..."

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
if [ ! -f .env.local ]; then
    echo "âŒ .env.local íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!"
    exit 1
fi

# ë¡œì»¬ Ollama í™•ì¸
echo "ğŸ¤– ë¡œì»¬ Ollama í™•ì¸ ì¤‘..."
if ! curl -s http://localhost:11434/api/version > /dev/null; then
    echo "âŒ Ollamaê°€ ì‹¤í–‰ë˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤!"
    echo "ğŸ’¡ 'ollama serve'ë¡œ Ollamaë¥¼ ë¨¼ì € ì‹œì‘í•˜ì„¸ìš”."
    exit 1
fi

# Ollama ëª¨ë¸ í™•ì¸
echo "ğŸ“¦ Ollama ëª¨ë¸ í™•ì¸ ì¤‘..."
if ! ollama list | grep -q "qwen2.5:latest"; then
    echo "ğŸ“¥ qwen2.5:latest ë‹¤ìš´ë¡œë“œ ì¤‘..."
    ollama pull qwen2.5:latest
fi

# Docker ì´ë¯¸ì§€ ë¹Œë“œ
echo "ğŸ“¦ Docker ì´ë¯¸ì§€ ë¹Œë“œ ì¤‘..."
docker compose build

# ì„œë¹„ìŠ¤ ì‹œì‘
echo "ğŸ¬ ì„œë¹„ìŠ¤ ì‹œì‘ ì¤‘..."
docker compose up -d

# í—¬ìŠ¤ì²´í¬
echo "ğŸ¥ í—¬ìŠ¤ì²´í¬ ëŒ€ê¸° ì¤‘..."
sleep 10
curl -f http://localhost:3000/api/health || exit 1

echo "âœ… ë°°í¬ ì™„ë£Œ!"
echo "ğŸŒ ì•± URL: http://localhost:3000"
echo "ğŸ“Š Portainer: http://localhost:9000"
echo "ğŸ¤– Ollama: http://localhost:11434 (ë¡œì»¬)"
```

### check-ollama.sh (Ollama í™•ì¸)
```bash
#!/bin/bash

echo "ğŸ” Ollama ìƒíƒœ í™•ì¸ ì¤‘..."

# Ollama í”„ë¡œì„¸ìŠ¤ í™•ì¸
if pgrep -x "ollama" > /dev/null; then
    echo "âœ… Ollama ì‹¤í–‰ ì¤‘"
else
    echo "âŒ Ollamaê°€ ì‹¤í–‰ë˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"
    echo "ğŸ’¡ 'ollama serve'ë¡œ ì‹œì‘í•˜ì„¸ìš”"
    exit 1
fi

# API ì‘ë‹µ í™•ì¸
if curl -s http://localhost:11434/api/version > /dev/null; then
    echo "âœ… Ollama API ì‘ë‹µ ì •ìƒ"
    echo "ğŸ“‹ ë²„ì „ ì •ë³´:"
    curl -s http://localhost:11434/api/version | jq
else
    echo "âŒ Ollama API ì‘ë‹µ ì—†ìŒ"
    exit 1
fi

# ì„¤ì¹˜ëœ ëª¨ë¸ í™•ì¸
echo ""
echo "ğŸ“¦ ì„¤ì¹˜ëœ ëª¨ë¸:"
ollama list

# qwen2.5:latest í™•ì¸
if ollama list | grep -q "qwen2.5:latest"; then
    echo "âœ… qwen2.5:latest ëª¨ë¸ ì„¤ì¹˜ë¨"
else
    echo "âš ï¸  qwen2.5:latest ëª¨ë¸ ì—†ìŒ"
    echo "ğŸ’¡ 'ollama pull qwen2.5:latest'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”"
fi
```

## Portainer Stack ì„¤ì •

Portainer UIì—ì„œ ì§ì ‘ ì„¤ì •:

1. **Stacks** â†’ **Add stack**
2. **Name**: `ai-personality-analyzer`
3. **Web editor**: ìœ„ì˜ `docker-compose.yml` ë‚´ìš© ë¶™ì—¬ë„£ê¸°
4. **Environment variables** ì¶”ê°€:
   ```
   SMTP_HOST=smtp.gmail.com
   SMTP_PORT=587
   SMTP_USER=your-email@gmail.com
   SMTP_PASS=your-app-password
   EMAIL_FROM=AI Personality <noreply@yourdomain.com>
   APP_URL=https://ai-personality.yourdomain.com
   ```
5. **Deploy the stack**

## ëª¨ë‹ˆí„°ë§

### ë¡œê·¸ í™•ì¸
```bash
# ì „ì²´ ë¡œê·¸
docker compose logs -f

# Next.js ë¡œê·¸ë§Œ
docker compose logs -f nextjs

# Ollama ë¡œê·¸ë§Œ
docker compose logs -f ollama
```

### ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
```bash
docker stats
```

### ì»¨í…Œì´ë„ˆ ìƒíƒœ
```bash
docker compose ps
```

## ë°±ì—…

### ë°ì´í„° ë°±ì—…
```bash
#!/bin/bash
# backup.sh

BACKUP_DIR="./backups/$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

# SQLite ë°±ì—…
cp ./data/database.sqlite "$BACKUP_DIR/"

# ìºì‹œ ë°±ì—… (ì„ íƒì‚¬í•­)
cp -r ./.cache "$BACKUP_DIR/"

echo "âœ… ë°±ì—… ì™„ë£Œ: $BACKUP_DIR"
```

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Ollama ì—°ê²° ì‹¤íŒ¨ (ë¡œì»¬ Ollama)
```bash
# 1. ë¡œì»¬ Ollama ì‹¤í–‰ í™•ì¸
pgrep -x ollama || echo "Ollamaê°€ ì‹¤í–‰ë˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"

# 2. Ollama ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
ollama serve &

# 3. API í…ŒìŠ¤íŠ¸
curl http://localhost:11434/api/version

# 4. Docker ì»¨í…Œì´ë„ˆì—ì„œ ì ‘ê·¼ í…ŒìŠ¤íŠ¸
docker exec -it ai-personality-nextjs curl http://host.docker.internal:11434/api/version

# 5. ë°©í™”ë²½ í™•ì¸ (macOS)
# ì‹œìŠ¤í…œ ì„¤ì • > ë³´ì•ˆ ë° ê°œì¸ì •ë³´ë³´í˜¸ > ë°©í™”ë²½ì—ì„œ Ollama í—ˆìš©
```

### ì´ë©”ì¼ ì „ì†¡ ì‹¤íŒ¨
```bash
# Next.js ë¡œê·¸ì—ì„œ SMTP ì—ëŸ¬ í™•ì¸
docker logs ai-personality-nextjs | grep -i smtp

# SMTP ì—°ê²° í…ŒìŠ¤íŠ¸
docker exec -it ai-personality-nextjs node -e "
const nodemailer = require('nodemailer');
const transporter = nodemailer.createTransport({
  host: process.env.SMTP_HOST,
  port: process.env.SMTP_PORT,
  auth: { user: process.env.SMTP_USER, pass: process.env.SMTP_PASS }
});
transporter.verify().then(console.log).catch(console.error);
"
```

### ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±
```bash
# ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” Docker ë¦¬ì†ŒìŠ¤ ì •ë¦¬
docker system prune -a --volumes

# Ollama ëª¨ë¸ í™•ì¸
docker exec ai-personality-ollama ollama list
```
