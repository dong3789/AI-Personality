import type { GitHubRepoData, AIPersonality, AIType } from './types';

const OLLAMA_API_URL = process.env.OLLAMA_API_URL || 'http://localhost:11434';

/**
 * Ollama LLMì„ ì‚¬ìš©í•œ ë ˆí¬ì§€í† ë¦¬ ë¶„ì„
 */
export async function analyzeWithLLM(
  repoData: GitHubRepoData
): Promise<AIPersonality> {
  const prompt = generatePrompt(repoData);

  try {
    const response = await fetch(`${OLLAMA_API_URL}/api/generate`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: 'qwen2.5:14b',
        prompt,
        stream: false,
        format: 'json',
        options: {
          temperature: 0.7,
          top_p: 0.9,
        },
      }),
    });

    if (!response.ok) {
      throw new Error(`Ollama API ì—ëŸ¬: ${response.statusText}`);
    }

    const data = await response.json();
    const result = JSON.parse(data.response);

    // AI íƒ€ì…ë³„ ì´ëª¨ì§€ ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€
    return enrichResult(result);
  } catch (error) {
    console.error('LLM ë¶„ì„ ì—ëŸ¬:', error);

    // Fallback: ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë¶„ì„
    return fallbackAnalysis(repoData);
  }
}

/**
 * LLM í”„ë¡¬í”„íŠ¸ ìƒì„±
 */
function generatePrompt(repoData: GitHubRepoData): string {
  const languageList = Object.entries(repoData.languages)
    .map(([lang, bytes]) => `${lang}: ${bytes} bytes`)
    .join('\n');

  const commitMessages = repoData.recentCommits
    .slice(0, 5)
    .map((c) => `- ${c.message}`)
    .join('\n');

  const readmePreview = repoData.readmeContent
    .substring(0, 2000)
    .replace(/\n+/g, '\n');

  return `ë‹¹ì‹ ì€ GitHub ë ˆí¬ì§€í† ë¦¬ë¥¼ ë¶„ì„í•˜ì—¬ "ì–´ë–¤ AI ëª¨ë¸ íƒ€ì…ê³¼ ê°€ì¥ ë¹„ìŠ·í•œê°€"ë¥¼ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒ GitHub ë ˆí¬ì§€í† ë¦¬ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì„¸ìš”:

**ë ˆí¬ì§€í† ë¦¬**: ${repoData.name}
**ì„¤ëª…**: ${repoData.description || 'ì—†ìŒ'}
**ì£¼ ì–¸ì–´**: ${repoData.language || 'ì•Œ ìˆ˜ ì—†ìŒ'}
**Stars**: ${repoData.stars}, **Forks**: ${repoData.forks}
**ìƒì„±ì¼**: ${repoData.createdAt}
**í…ŒìŠ¤íŠ¸**: ${repoData.hasTests ? 'ìˆìŒ' : 'ì—†ìŒ'}
**CI/CD**: ${repoData.hasCICD ? 'ìˆìŒ' : 'ì—†ìŒ'}

**ì–¸ì–´ ë¶„í¬**:
${languageList}

**ìµœê·¼ ì»¤ë°‹ ë©”ì‹œì§€**:
${commitMessages}

**README ë‚´ìš©**:
${readmePreview}

---

ë‹¤ìŒ 8ê°€ì§€ AI ëª¨ë¸ íƒ€ì… ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:

1. **GPT-4** (The Perfectionist): ì™„ë²½ì£¼ì˜ì, ì² ì €í•œ ë¬¸ì„œí™”, ë†’ì€ ì½”ë“œ í’ˆì§ˆ
2. **GPT-3.5** (The Pragmatist): ì‹¤ìš©ì£¼ì˜ì, ë¹ ë¥¸ êµ¬í˜„, íš¨ìœ¨ì„± ì¤‘ì‹œ
3. **Claude Opus** (The Architect): ì„¤ê³„ì, ì²´ê³„ì  êµ¬ì¡°, ì•ˆì „ì„± ê°•ì¡°
4. **Claude Sonnet** (The Balanced Creator): ê· í˜•ì¡íŒ, ì°½ì˜ì , í˜‘ì—… ì¹œí™”ì 
5. **Gemini** (The Multi-Tasker): ë‹¤ì¬ë‹¤ëŠ¥, ì—¬ëŸ¬ ì–¸ì–´ ì‚¬ìš©, ì‹¤í—˜ì 
6. **Llama** (The Open Source Champion): ì˜¤í”ˆì†ŒìŠ¤ ì •ì‹ , ì»¤ë®¤ë‹ˆí‹° ì¤‘ì‹¬
7. **Mistral** (The Efficient Minimalist): ë¯¸ë‹ˆë©€ë¦¬ìŠ¤íŠ¸, íš¨ìœ¨ì„± ê·¹ëŒ€í™”, ê°„ê²°
8. **Cohere** (The Specialist): íŠ¹ì • ë¶„ì•¼ ì „ë¬¸í™”, ì„±ëŠ¥ ìµœì í™”

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "aiType": "GPT-4|GPT-3.5|Claude Opus|Claude Sonnet|Gemini|Llama|Mistral|Cohere",
  "confidence": 85,
  "reasoning": "ì„ íƒí•œ ì´ìœ ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ",
  "traits": ["íŠ¹ì§•1", "íŠ¹ì§•2", "íŠ¹ì§•3"],
  "strengths": ["ê°•ì 1", "ê°•ì 2"],
  "funnyComment": "ì¬ë¯¸ìˆëŠ” í•œ ì¤„ ì½”ë©˜íŠ¸ (í•œêµ­ì–´)"
}`;
}

/**
 * LLM ê²°ê³¼ì— ë©”íƒ€ë°ì´í„° ì¶”ê°€
 */
function enrichResult(result: any): AIPersonality {
  const aiTypeMetadata: Record<AIType, { emoji: string; title: string }> = {
    'GPT-4': {
      emoji: 'ğŸ§ ',
      title: 'GPT-4í˜•: ë§ŒëŠ¥ í•´ê²°ì‚¬',
    },
    'GPT-3.5': {
      emoji: 'âš¡',
      title: 'GPT-3.5í˜•: ì‹¤ìš©ì£¼ì˜ì',
    },
    'Claude Opus': {
      emoji: 'ğŸ“š',
      title: 'Claude Opusí˜•: ì‹ ì¤‘í•œ ì™„ë²½ì£¼ì˜ì',
    },
    'Claude Sonnet': {
      emoji: 'âœ¨',
      title: 'Claude Sonnetí˜•: ê· í˜•ì¡íŒ ì°½ì‘ì',
    },
    Gemini: {
      emoji: 'ğŸŒŸ',
      title: 'Geminií˜•: í˜ì‹ ì ì¸ ì‹¤í—˜ê°€',
    },
    Llama: {
      emoji: 'ğŸ¦™',
      title: 'Llamaí˜•: ì˜¤í”ˆì†ŒìŠ¤ ì „ë„ì‚¬',
    },
    Mistral: {
      emoji: 'ğŸŒªï¸',
      title: 'Mistralí˜•: íš¨ìœ¨ì˜ ë‹¬ì¸',
    },
    Cohere: {
      emoji: 'ğŸ”',
      title: 'Cohereí˜•: ì² í•™í•˜ëŠ” ì½”ë”',
    },
  };

  const aiType = result.aiType as AIType;
  const metadata = aiTypeMetadata[aiType];

  return {
    aiType,
    confidence: result.confidence || 80,
    emoji: metadata.emoji,
    title: metadata.title,
    oneLiner: result.reasoning || '',
    traits: result.traits || [],
    strengths: result.strengths || [],
    funnyComment: result.funnyComment || 'ë¶„ì„ ì™„ë£Œ!',
    matchScore: result.confidence || 80,
  };
}

/**
 * Fallback ë¶„ì„ (LLM ì‹¤íŒ¨ ì‹œ)
 */
function fallbackAnalysis(repoData: GitHubRepoData): AIPersonality {
  // ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë¶„ì„
  let aiType: AIType = 'GPT-3.5';

  const readmeLength = repoData.readmeContent.length;
  const languageCount = Object.keys(repoData.languages).length;

  if (readmeLength > 5000 && repoData.hasTests) {
    aiType = 'GPT-4';
  } else if (languageCount >= 5) {
    aiType = 'Gemini';
  } else if (repoData.hasCICD) {
    aiType = 'Claude Opus';
  }

  return enrichResult({
    aiType,
    confidence: 70,
    reasoning: 'ìë™ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.',
    traits: ['ë¶„ì„ë¨', 'ìë™ íŒì •'],
    strengths: ['ê¸°ë³¸ ë¶„ì„'],
    funnyComment: 'LLM ë¶„ì„ì´ ì‹¤íŒ¨í•˜ì—¬ ê°„ë‹¨íˆ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.',
  });
}

/**
 * Ollama ì—°ê²° í™•ì¸
 */
export async function checkOllamaConnection(): Promise<boolean> {
  try {
    const response = await fetch(`${OLLAMA_API_URL}/api/version`, {
      method: 'GET',
    });
    return response.ok;
  } catch (error) {
    return false;
  }
}
